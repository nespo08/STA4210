---
title: "Homework 2"
author: "Nicholas Esposito"
date: "10/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, results=FALSE}
# Load packages
library(lmtest)
```


### Load the data

Y - Deflection of galvonometer, X - Area of the wires on the coupling

```{r, echo = FALSE}
exp_data <- read.table("https://users.stat.ufl.edu/~winner/data/explosives1.dat",
                       header = F, col.names = c("coupling", "areaWire", "defGalv"))
```

### a) The fitted equation and residuals

The fitted equation for the simple linear model relating the deflection of galvonometer (Y) to the area of the wires on the coupling (X) is: 

Y = 184.436 - 0.695X

```{r, echo = FALSE}
X <- exp_data$areaWire
Y <- exp_data$defGalv
lm_exp_data <- lm(Y ~ X)

# ADD BY HAND CALCULATION

summary(lm_exp_data)
```
The residuals are:

```{r, echo = FALSE}
residuals <- resid(lm_exp_data)
residuals
```

### b) Plot of Y vs X

```{r}
plot(Y ~ X, main = "Deflection of Galvonomete (Y) vs Area of the Wires on the Coupling (X)")
abline(lm_exp_data)
```

c) Residual Plot of e vs X

```{r}
plot(X, residuals, main = "Residuals vs Predictors (X)")
abline(lm_exp_data)
```

d) A test of whether deflections (Y) are associated with area of the wires (X)

Use Pearson's correlation test to test H0: p = 0 versus Ha: p != 0 (alpha=0.05).

Test-Statistic (t*): -20.557
Critical Value, or t(0.975, 20): 2.086
Rejection Region: |t*| >= t(0.975, 20)

Since |-20.557| >= 2.086, the test statistic t* is statistically significant at alpha = 0.05. Thus, we reject the null hypothesis H0: p = 0 and conclude that there is a linear association between deflections (Y) and area of the wires (X).

```{r}
cor.test(X,Y) # Pearson's correlation test

# ADD BY HAND CALCULATION

SSyy <- sum()
```

e) Normal Probability Plot of the residuals

```{r}
qqnorm(residuals)
qqline(residuals)
```

f) Shapiro-Wilk test for normality 

H0: The errors follow a normal distribution.

Ha: The errors do not follow a normal distribution.

The Shapiro-Wilk test produces a p-value of 0.09. Since 0.09 > 0.05, we fail to reject H0, and thus conclude that the residuals follow a normal distribution at the significance level 0.05.

```{r}
shapiro.test(residuals)
```

g) Brown-Forsyth test for constant variance 

H0: There is equal variance among the errors.

Ha: There is unequal variance among the errors (Increasing or Decreasing in X).

We have test statistic t* = -0.5534, and will compare it against t(0.975, 20) = 2.086.

Since |t*| = 0.5534 < 2.086, we fail to reject H0, and thus conclude that there is equal variance among the errors at the significance level 0.05.

```{r}
group.BF <- ifelse(exp_data$coupling <= 4, 1, 2) # Breaks the data by coupling value

fit1 <- lm(exp_data$defGalv ~ exp_data$areaWire)
res1 <- resid(fit1)

median_e1 <- median(residuals[group.BF == 1]) # Median residuals
median_e2 <- median(residuals[group.BF == 2])

median_e <- rep(c(median_e1, median_e2), each = 11)

d.BF <- abs(res1 - median_e)
cbind(group.BF, d.BF)

# Brute force calculation 
dbar1 <- mean(d.BF[group.BF == 1])
dbar2 <- mean(d.BF[group.BF == 2])

var1 <- var(d.BF[group.BF == 1])
var2 <- var(d.BF[group.BF == 2])

n1 <- length(d.BF[group.BF == 1])
n2 <- length(d.BF[group.BF == 2])

var.p <- ((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2) # Pooled variance

t.BF <- (dbar1 - dbar2) / sqrt(var.p*(1/n1 + 1/n2)) # T-statistic

p.t.BF <- 2*(1-pt(abs(t.BF), n1+n2-2)) # P-value

BF.out <- cbind(dbar1 - dbar2, t.BF, p.t.BF)
colnames(BF.out) <- c("Mean Diff", "t*", "2P(>|t*|))")
rownames(BF.out) <- c("BF Test")
round(BF.out, 4)
```

h) Breusch-Pagan Test for constant variance

H0: There is equal variance among the errors.

Ha: There is unequal variance among the errors.

We have test statistic X^2* = 2.5916, and will compare it against X^2(0.95, 1) = 3.8415.

Since X^2* = 2.5916 < 3.8415, we fail to reject H0, and thus conclude that there is equal variance among the errors at the significance level 0.05.

```{r}
#bptest(lm_exp_data)

# 1. Find ei^2
residuals.sq <- residuals^2

# 2. Fit Regression of ei^2 on X
lm.BP <- lm(residuals.sq ~ X)
summary(lm.BP)

newR.sq <- 0.1178 # From summary of new linear model
chi.sq <- newR.sq * 22 # 22 observations

crit.X <- qchisq(0.95, 1, lower.tail=TRUE)

# Output
BP.out <- cbind(chi.sq, crit.X)
colnames(BP.out) <- c("Chi-Sq*", "Crit. Value")
rownames(BP.out) <- c("BP Test")
round(BP.out, 4)
```

i) F-test for lack-of-fit 

H0: E(Yi) = B0 + B1Xi - there is no lack of fit in the model.

Ha: E(Yi) != B0 + B1Xi - there is lack of fit in the model.

We have the test statistic F* = 7.8407. Our p-value is 0.0007684.

Since 0.0007684 < 0.05, we reject H0, and thus conclude that there is lack of fit in the model at the significance level 0.05.

```{r}
# Full vs. reduced
lm_exp_data_full <- lm(Y ~ factor(X))
lm_exp_data_reduced <- lm(Y ~ X)
anova(lm_exp_data_reduced, lm_exp_data_full)
```

j) Obtain “best” power transformation method, based on Box-Cox transformations (HAVE TO INTERPRET THIS - SEE NOTES/PPT)

```{r}

```


k) Obtain simultaneous 95% Confidence Intervals for B0, B1

l) Obtain an approximate 95% Confidence Interval for the Area of the coupling, 
when a deflection of 115 was observed (See section 4.6)

m) Obtain X’X, X’Y, (X’X)-1, beta-hat, MSE, and s2{beta-hat}

X' -> X^T 
(X'X)-1 is the inverse of X^T*X
